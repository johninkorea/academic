{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "seed=1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning with mps\n"
     ]
    }
   ],
   "source": [
    "## device choice\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_built()  else 'cpu'\n",
    "\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'mps':\n",
    "    # torch.backends.mps.manual_seed_all(seed)\n",
    "    torch.backends.mps.is_available()\n",
    "\n",
    "print(\"learning with\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=int(1e2) # number of data\n",
    "x=np.linspace(-.9,.9,N)\n",
    "y=np.sin(x)\n",
    "\n",
    "idx_train=(np.random.choice(N,80,replace=0))\n",
    "idx_test = np.setdiff1d(np.arange(N), idx_train)\n",
    "\n",
    "x_train=x[idx_train]\n",
    "y_train=y[idx_train]\n",
    "\n",
    "x_test=x[idx_test]\n",
    "y_test=y[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_data, y_data): # 데이터섹을 전처리\n",
    "        self.x_data= x_data\n",
    "        self.y_data= y_data\n",
    "\n",
    "    def __len__(self): # 데이터섹을 총 샘플의 수를 적는 부분\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx): # 데이터셋에서 특정 하나를 가져오는 함수\n",
    "        x=torch.FloatTensor(self.x_data[idx])\n",
    "        y=torch.FloatTensor(self.y_data[idx])\n",
    "        return x,y\n",
    "\n",
    "# 학습 시킬 데이터를 받고, 그러를 함수로 묶고 정리해서 _train으로 만든다.\n",
    "dataset=Customdataset(x_train,y_train)\n",
    "dataloader=DataLoader(dataset,batch_size=2, shuffle=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NN.forward of NN(\n",
      "  (layer_in): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer_hidden): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer_out): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (hidden): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# 신경망 정의\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num1, num2):\n",
    "        self.num1 = num1 # nodes per hidden layer\n",
    "        self.num2 = num2 # number of hidden layer\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "        self.layer_in = nn.Sequential(\n",
    "            nn.Linear(1,self.num1),\n",
    "            nn.ReLU())\n",
    "        self.layer_hidden = nn.Sequential(\n",
    "            nn.Linear(self.num1,self.num1),\n",
    "            nn.ReLU())\n",
    "        self.layer_out = nn.Sequential(\n",
    "            nn.Linear(self.num1,1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.hidden=nn.ModuleList()\n",
    "        for i in range(self.num2):\n",
    "            self.hidden.append(self.layer_hidden)\n",
    "        \n",
    "        \n",
    "        # 가중치를 고르게하는 건데 이 잘 안돼네....\n",
    "        # nn.init.xavier_uniform_(self.layer1.weight) # 지금까지는 대충 설정했는데\n",
    "        # nn.init.xavier_uniform_(self.layer2.weight) # 지금까지는 대충 설정했는데\n",
    "\n",
    "    def forward(self, x): # 순서대로 대입해서 출력하는 것뿐 \n",
    "        out = self.layer_in(x)\n",
    "        for layer in self.hidden:\n",
    "            out = layer(out)\n",
    "        out = self.layer_out(out)\n",
    "        return out\n",
    "\n",
    "model = NN(3,1).to(device)\n",
    "print(model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'num1' and 'num2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yararal/1code/academic/main/1.hyperparameter_gen/1_nn_macgpu.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yararal/1code/academic/main/1.hyperparameter_gen/1_nn_macgpu.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yararal/1code/academic/main/1.hyperparameter_gen/1_nn_macgpu.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m NN()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yararal/1code/academic/main/1.hyperparameter_gen/1_nn_macgpu.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yararal/1code/academic/main/1.hyperparameter_gen/1_nn_macgpu.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'num1' and 'num2'"
     ]
    }
   ],
   "source": [
    "## training\n",
    "model = NN().to(device)\n",
    "\n",
    "lr=1e-5\n",
    "epochs=20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "cos_histroy=[]\n",
    "for epoch in range(epochs+1):\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        x_train,y_train=sample\n",
    "\n",
    "        prediction=model(x_train)\n",
    "        cos=F.mse_loss(prediction,y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cos.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, epochs, batch_idx+1, len(dataloader),cos.item()\n",
    "        ))\n",
    "    cos_histroy.append(cos.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(epochs+1),cos_histroy)\n",
    "plt.xlim([5,21])\n",
    "plt.ylim([0,3])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 이번에 도 들죽날쭋하네\n",
    "# 셔플 텨져있음.\n",
    "\n",
    "in_val=torch.FloatTensor([73,80,75])\n",
    "out_val=model(in_val)\n",
    "print(out_val.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40811b77fc361d43600929cc59d905b06e0cebb6488c8210251e2e33ec87a75f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
